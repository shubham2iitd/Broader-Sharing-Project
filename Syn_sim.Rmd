
```{r}
library(readxl)
library(openxlsx)
library(maptools)
library(foreign)
library(plyr)
library(fastDummies)
library(Matrix)
library(pracma)
library(SQUAREM)
library(nleqslv)
library(wordspace)
library(data.table)
library(ggplot2)
library(haven)
library(tibble)
```

Load required datasets:
```{r}
ana_OPO = "CADN/Till_30_sept/Oct1/"
dff = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/temp_Julia/", ana_OPO, "/dff_COX_G2_48org_det_waitcost_NoN_after_Y.csv"))
dff_wait_cost = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/temp_Julia/", ana_OPO, "/dff_wait_cost_COX_G2_48org_det_waitcost_NoN_after_Y.csv"))
pi_pre = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/temp_Julia/", ana_OPO, "/pi_pre_COX_G2_48org_det_waitcost_NoN_after_Y_all_ofr_trns_v3_aprch2.csv"))
pi_post = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/temp_Julia/", ana_OPO, "/pi_post_COX_G2_48org_det_waitcost_NoN_after_Y_all_ofr_trns_v3_aprch2.csv"))

det_waitcost = 1
```

```{r}
# rem_intercept_wait_cost = 1
# if (rem_intercept_wait_cost == 1) {
#   dff_wait_cost = dff_wait_cost_src[, -which(names(dff_wait_cost_src) == "intercept")]
# }
```

```{r}
# match1 = match1[!(match1$new_PTR_STAT_CD_desp == "MELD/PELD 46"), ]
# match1$new_PTR_STAT_CD_desp = as.character(match1$new_PTR_STAT_CD_desp)
```

# Input parameters:
```{r}
delta = 0.95

inp_vec = c(-15.2376000,
-0.6556400,
-2.4350700,
11.6883000,
3, # -1.3010400,
3,#3.9356400,
0.0381068,
0.0441496,
0.0437912,
-0.0304777)

a = inp_vec[1:4]
w = inp_vec[5:length(inp_vec)]
```

# To estimate EV_vec:
```{r}
# Coerce EU = 0 for inactive, died (irrespective of organ offer (if any)) and no offer (irrespective of MELD), to get the required specification!
EU_0_row_idx = which(dff$org_age_type == "no_offer")   # Instead of 'org_age_type', it can be anything that has 'no_offer' in it.

# Expected utility:
# Dimension: Cardinality(State space) x 1
EU_vec = function(a, df_S_it) { 
  EU_0_row_idx = which(df_S_it$org_age_type == "no_offer")
  mat =  Matrix(as.matrix(df_S_it[, c("intercept", "sharing_type_regional", "sharing_type_national", "mean_GSi")]), sparse = T)
  val = mat %*% a
  # Coerce EU = 0 for inactive, died (irrespective of organ offer (if any)) and no offer (irrespective of MELD), to get the required specification!
  val[EU_0_row_idx] = 0
  return (as.vector(val))
}
sum(EU_vec(a = rep(0.3, 4), df_S_it = dff))

wait_cost_vec = function(w, dff_wait_cost) {     # 'organ type' should NOT be part of it:
  mat = Matrix(as.matrix(dff_wait_cost), sparse = T)     # Sparse matrix
  val = mat %*% w
  return (as.vector(val))
}
sum(wait_cost_vec(w = w, dff_wait_cost = dff_wait_cost))

# Dimension: Cardinality(State space) x 1
EV_vec_inmt = function(EV_vec_cand, a, w, pi, delta, df_S_it, dff_wait_cost, contrc_f) {    # Add "X_it" in the parameter
  temp_df = data.frame(EU_vec_col = EU_vec(a, df_S_it),
                       nxt_epoch_uti_col = - wait_cost_vec(w, dff_wait_cost) + delta * EV_vec_cand)
  rhs = log(exp(temp_df$EU_vec_col) + exp(temp_df$nxt_epoch_uti_col))
  #
  rhs[EU_0_row_idx] = temp_df$nxt_epoch_uti_col[EU_0_row_idx]
  #
  # Since 'pi' (full transition probability matrix (MELD, q) does not depend on X_it, we can partition the 'temp_df' and calculate "val" separately for each X_it)
  
  val = c(); contrc_f_val = c()
  if (det_waitcost == 1) {
    df_S_it$rec_type = paste(df_S_it$rec_age_type, df_S_it$rec_life_sup, df_S_it$rec_med_cond, sep = "|")
  } else {df_S_it$rec_type = df_S_it$rec_age_type}
  
  for (X_it in unique(df_S_it[, "rec_type"])) {     # rec_age_travel_time, X_it + travel_time_it won't take more than 10 values I guess, so 'for' loop is fine!
    idx_range = which(df_S_it[, "rec_type"] == X_it)
    val_ = EV_vec_cand[idx_range] - pi %*% rhs[idx_range]    # val = EV_vec_cand - pi %*% rhs
    #print (as.vector(val_))
    val = c(val, as.vector(val_))
    contrc_f_val = c(contrc_f_val, as.vector(pi %*% rhs[idx_range]))
  }
  if (contrc_f == 1) {return (contrc_f_val)}
  return (as.vector(val))
}

# EV_vec_inmt(EV_vec_cand = rep(.3, nrow(dff)), a, w, as.matrix(pi_pre), delta = 0.95, df_S_it = dff, dff_wait_cost, contrc_f = 1)

# Pre-SHARE 35 policy:
# max(EV_vec_inmt(EV_vec_cand = EV_vec0$par, 
#            a = inp_vec[1:22], w = inp_vec[23:35], pi = normalize.rows(as.matrix(trans_df_OPO_pre[, -c(1:8)]), method = 'manhattan'), delta = 0.95, df_S_it = dff, cols_to_rem_frm_strt = 7, contrc_f = 0))

Sys.time()
EV_vec0 = squarem(fixptfn = EV_vec_inmt, par = rep(.3, nrow(dff)), control = list(maxiter = 1000, tol = 1e-8),
         a = a, w = w, pi = as.matrix(pi_pre), delta = 0.95, df_S_it = dff[, ], dff_wait_cost = dff_wait_cost, contrc_f = 1)   # Sys.time()
sum(abs(EV_vec_inmt(EV_vec0$par, a = a, w = w, pi = as.matrix(pi_pre), delta = 0.95, df_S_it = dff[, ], dff_wait_cost = dff_wait_cost, contrc_f = 0)))

# system.time(squarem(fixptfn = EV_vec_inmt, par = runif(1993*2, min = 1, max = 7), control = list(maxiter = 100, tol = 1e-13), 
#         a = rep(1, 22), w = rep(0.3, 13), pi = normalize.rows(as.matrix(trans_df_OPO_pre[, -c(1:8)]), method = 'manhattan'), delta = 0.95, df_S_it = dff[, ], cols_to_rem_frm_strt = 8, rem_X_it_name_col = c("rec_age_type"), contrc_f = 1))
```

# Contraction mapping to estimate EV_vec
```{r}
EV_vec_pre = data.frame(dff[, c(1:9)], EV_vec_pre_val = squarem(fixptfn = EV_vec_inmt, par = runif(nrow(dff), min = 1, max = 7), control = list(maxiter = 5000, tol = 1e-15), 
         a=a, w=w, pi = as.matrix(pi_pre), delta = 0.95, df_S_it = dff[, ], dff_wait_cost = dff_wait_cost, contrc_f = 1)$par)

EV_vec_post = data.frame(dff[, c(1:9)], EV_vec_post_val = squarem(fixptfn = EV_vec_inmt, par = runif(nrow(dff), min = 1, max = 7), control = list(maxiter = 5000, tol = 1e-15), 
         a=a, w=w, pi = as.matrix(pi_post), delta = 0.95, df_S_it = dff[, ], dff_wait_cost = dff_wait_cost, contrc_f = 1)$par)
```

# Using actual data:
```{r}
# PROBLEM WITH USING THE ACTUAL DATA IS THAT THERE ARE MANY "STATES" FOR WHICH NO OBSERVATIONS ARE THERE, BUT SOME PROBABILITY GET ASSIGNED (exp() / (exp() + exp()))!, THEREFORE, WE WILL ALWAYS GET 'OVERESTIMATES', IF WE SUM UP prob!

# match1_pre = match1[match1$policy == "pre", c("new_PTR_STAT_CD_desp", "type", "rec_age_type", "travel_time_type")]
# names(match1_pre)[grep("new_PTR_STAT_CD_desp", colnames(match1_pre))] = "MELD"
# spl = strsplit(as.character(match1_pre$type), split = "_")
# match1_pre$org_age_type = sapply(spl, "[", 1)
# match1_pre$org_race_type = sapply(spl, "[", 2)
# match1_pre$org_cod_type = sapply(spl, "[", 3)
# match1_pre$org_dcd_type = sapply(spl, "[", 4)
# match1_pre$intercept = 1
# temp = merge(match1_pre, EV_vec_pre, all.x = T)
# temp = temp$EV_vec_pre_val
# 
# match1_pre = dummy_cols(match1_pre[, -which(names(match1_pre) == "type")], remove_first_dummy = F)
# match1_pre = match1_pre[, -c(1:7, which(names(match1_pre) %in% c("MELD_MELD/PELD 6-14", "org_age_type_A1", "org_race_type_White", "org_cod_type_Other", "org_dcd_type_No", "rec_age_type_RA1", "travel_time_type_TT1")))]
# 
# # Re-order the columns as are the coefficients ("inp_par"):
# match1_pre = match1_pre[, c("intercept", "MELD_MELD/PELD 15-24", "MELD_MELD/PELD 25-29", "MELD_MELD/PELD 30-34", "MELD_MELD/PELD 35", "MELD_MELD/PELD 36", "MELD_MELD/PELD 37", "MELD_MELD/PELD 38", "MELD_MELD/PELD 39", "MELD_MELD/PELD 40", "MELD_Status 1", "org_age_type_A2", "org_age_type_A4", "org_age_type_A3", "org_age_type_A5", "org_race_type_Other", "org_cod_type_CVA", "org_cod_type_Anoxia", "org_dcd_type_Yes", "rec_age_type_RA2", "travel_time_type_TT2")]
# 
# match1_pre$exp_EU = Matrix(as.matrix(match1_pre), sparse = T) %*% inp_vec[1:21]
# match1_pre$wait_cost = Matrix(as.matrix(match1_pre[, c(1:11, 20)]), sparse = T) %*% c(inp_vec[22:32], inp_vec[34])  # Since coef of "Temporarily Inactive" = 0!
# #match1_pre = merge(match1_pre, EV_vec_pre, by = "state", all.x = T)  ?? policy??
# match1_pre$den = match1_pre$exp_EU + exp(-match1_pre$wait_cost + delta * temp)
# match1_pre$prob_accept = match1_pre$exp_EU / match1_pre$den
# 
# sum(match1_pre$prob_accept) / nrow(match1_pre)
# table(match1[match1$policy == "pre", ]$PTR_OFFER_ACPT)
```

# Create synthetic data:
```{r}
syn_df = dff[, c("org_age_type", "org_race_type", "org_cod_type", "org_dcd_type", "MELD", "rec_age_type", "sharing_type")]
syn_df$state = paste(paste(syn_df$org_age_type, syn_df$org_race_type, syn_df$org_cod_type, syn_df$org_dcd_type, sep = "_"), syn_df$MELD, syn_df$rec_age_type, syn_df$sharing_type, sep = " & ")
syn_df$S_it_idx = c(1:nrow(syn_df))

syn_df$EU = EU_vec(a, df_S_it = dff)
syn_df$wait_cost = wait_cost_vec(w, dff_wait_cost)
syn_df$EV_vec_pre = EV_vec_pre$EV_vec_pre_val
syn_df$EV_vec_post = EV_vec_post$EV_vec_post_val

syn_df = syn_df[-which(syn_df$org_age_type == "no_offer"), ]   # Remove 'states' that are associated with 'no_offer'.

syn_df$P_accept_pre = exp(syn_df$EU) / (exp(syn_df$EU) + exp(-syn_df$wait_cost + delta * syn_df$EV_vec_pre))
syn_df$P_accept_post = exp(syn_df$EU) / (exp(syn_df$EU) + exp(-syn_df$wait_cost + delta * syn_df$EV_vec_post))

sum(syn_df$P_accept_pre); sum(syn_df$P_accept_post)

# Make "n" copies: a total of 3172*100*2 (pre/post) = 634,400; But we only need 'n_accept', and 'n_decline'!
n = 1000
syn_df_pre = syn_df[, c("state", "S_it_idx", "P_accept_pre")]
syn_df_pre$n_accept = round(syn_df_pre$P_accept_pre * n, 0)
syn_df_pre$n_decline = n - syn_df_pre$n_accept

syn_df_post = syn_df[, c("state", "S_it_idx", "P_accept_post")]
syn_df_post$n_accept = round(syn_df_post$P_accept_post * n, 0)
syn_df_post$n_decline = n - syn_df_post$n_accept
```

```{r}
write.csv(syn_df_pre, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/temp_Julia/", ana_OPO, "/fixed_Died3/syn_df_pre_G2_48org_det_waitcost_", n, "_fixedDied3_3.csv"))   # _mod
write.csv(syn_df_post, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/temp_Julia/", ana_OPO, "/fixed_Died3/syn_df_post_G2_48org_det_waitcost_", n, "_fixedDied3_3.csv"))
```
























