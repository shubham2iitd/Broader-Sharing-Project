
```{r}
library(data.table)
library(readxl)
library(openxlsx)
library(ggplot2)
library(maptools)
library(foreign)
library(plyr)
library(haven)
library(dplyr)

print ("--")
```

```{r}
knitr::opts_knit$set(root.dir = normalizePath("/Volumes/GoogleDrive/My Drive/SRTR/R_files//"))
getwd()
```

```{r}
state_agg = 1
agg_level = "G6AC"
MELD_col_name = "CANHX_STAT_CD" # "CANHX_OPTN_LAB_MELD" # "CANHX_STAT_CD" # "CANHX_SRTR_LAB_MELD  # Columns to indicate the MELD during the WL period
del_multi_offers_in_a_day = 0

N_after_Y_filter = 1
rem_later_ofrs = 1

MELD_col_desp_name = paste0(MELD_col_name, "_desp")
sheet_MELD_class = paste0("transition_agg_", agg_level) # "transition_agg_G" # "transition_agg_SIMPLE"
stathist_liin_nxt_state_time_adj_file_name = paste0("/", agg_level, "/", MELD_col_name, "/stathist_liin_nxt_state_time_adj_", agg_level, "_", MELD_col_name, ".csv")
```

# Organ Arrival (Donor):
```{r}
don_src = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/donor.csv")
don_src$date <- as.Date(don_src$date, format= "%Y-%m-%d")
don_src$yr = substr(don_src$date, 1, 4)
don_src$date[2]

#temp = data.table(don_src)[, list(organ_per_month = .N/uniqueN(yr_mon)), by = list(yr_mon, DON_OPO_CTR_CD)]
# temp = data.table(don_src)[, list(cnt = .N), by = list(DON_OPO_CTR_CD, date, policy)]
# temp1 = subset(temp, cnt > 1)  # Given an organ arrived, on 23% dates, >1 organs arrived ; Overall, 14746/3344/59 = 7.5% days had >1 arrivals on a day in a DSA
# table(temp1$DON_OPO_CTR_CD)  # % of days with >1 arrivals is 1263/3344 = 38%

# Create 'DON_RACE_desp':
don_src$DON_RACE_desp = "Other"
don_src[don_src$DON_RACE == 8, "DON_RACE_desp"] = "White"
don_src[don_src$DON_RACE == 2000, "DON_RACE_desp"] = "Hispanic"
don_src[don_src$DON_RACE == 16, "DON_RACE_desp"] = "Black"
table(don_src$DON_RACE_desp)/nrow(don_src) # 66% White, 13.5% Hispanic, 17% Black, 3.5% Other
```

# Now, directly jump to (lines ~ 117, 118) reading "trns2" and "match1" files, if interested in 'organ_prob_cal':
# V.V.I.: TO DELETE MULTIPLE OFFERS OR NOT ????????????????
```{r}
if (del_multi_offers_in_a_day == 0) {
  match_src = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA_Z_2hrs_ACPT_MATCH_seq_PTR_upd_N_after_Y_CAN_DON_info.csv")
  match = match_src
  match$date = as.Date(match$date); min(match$date); max(match$date)
} else if (del_multi_offers_in_a_day == 1) {
  match = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_del_multiple_PX_ID_day_offers_GSi.csv")????
  match$date = as.Date(match$date)
}

# Adult patients:
match = subset(match, (!is.na(CAN_AGE_IN_MONTHS_AT_LISTING) & (CAN_AGE_IN_MONTHS_AT_LISTING >= 18*12)))

# "N_after_Y" filter:
if (N_after_Y_filter == 1) {
  match = subset(match, N_after_Y == 0)
}
```

# Remove 'Decline decisions' that were NOT due to "quality" reasons:
```{r}
table(match$PTR_TXC_REFUSAL_CD)
# table(match$PTR_TXC_REFUSAL_CD, match$PTR_PRIME_OPO_REFUSAL_ID)

non_qlty_CD = c(800, 801, 802, 803, 820, 823, 825, 836, 860)   # NOT sure about 824 (Distance to travel or ship), 835 (Organ Preservation)
non_qlty_CD = c(non_qlty_CD, 835)

match = subset(match, !(PTR_TXC_REFUSAL_CD %in% non_qlty_CD))  # nrow(temp)/nrow(match), 92.4% of the records are retained.

# Restrict 'PTR_SEQUENCE_upd':
if (rem_later_ofrs == 1) {
  match = data.table(match)[order(PTR_SEQUENCE_NUM),  PTR_SEQUENCE_NUM_upd:= rleid(PTR_SEQUENCE_NUM), by = c("MATCH_ID")]     # Replacing the contents of "PTR_SEQUENCE_NUM_upd" 
  match = data.frame(match)
  match = subset(match, PTR_SEQUENCE_NUM_upd <= 500)
}
```

# Update the match1's "PTR_STAT_CD_desp" column with the 'aggregated' definitions:
```{r}
# Aggregate the states in 'match1' file:
if (state_agg == 1) {
  ref = read_excel("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/ptr_li_sample.xlsx", sheet = sheet_MELD_class)
  match = merge(match, unique(ref[, c("CANHX_STAT_CD_desp", "new_CANHX_STAT_CD_desp")]), by.x = "PTR_STAT_CD_desp", by.y = "CANHX_STAT_CD_desp", all.x = T)
  match$PTR_STAT_CD_desp = match$new_CANHX_STAT_CD_desp
  match = match[, -which(names(match) %in% c("new_CANHX_STAT_CD_desp"))]
  
  match$PTR_STAT_CD_desp = as.character(match$PTR_STAT_CD_desp)
  table(match$PTR_STAT_CD_desp)
}
```

# Sharing to MELD >= 35 patients "post" Share35 is all 'local'!
```{r}
SkiP these....
unique(match$PTR_STAT_CD_desp); table(match$sharing)
if (grepl("G5", agg_level)) {
  col_lst = c("MELD/PELD >34")
} else if (grepl("G11", agg_level)) {
  col_lst = c("MELD/PELD 35", "MELD/PELD 36", "MELD/PELD 37", "MELD/PELD 38", "MELD/PELD 39", "MELD/PELD 40", "Status1")
} else if (grepl("G2", agg_level)) {
  col_lst = c("MELD_high")
}
match[(match$policy == "post") & (match$PTR_STAT_CD_desp %in% col_lst & (match$sharing == "regional")), "sharing"] = "local"
```

# REQUIRED (for organ_prob_cal) Estimating the 'Probability of receiving an offer':
```{r}
# Import state-transition data:
trns = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix//", stathist_liin_nxt_state_time_adj_file_name))
# names(trns)
# barplot(table(trns$CANHX_REASON_STAT_INACT) / nrow(trns))    # Reason Candidate Status made inactive
# write.csv(table(trns$CANHX_REASON_STAT_INACT), "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/CANHX_REASON_STAT_INACT_stat.csv", row.names = F)
# samp = trns[1:10, ]

trns$CANHX_BEGIN_DT = as.Date(trns$CANHX_BEGIN_DT); min(trns$CANHX_BEGIN_DT); max(trns$CANHX_BEGIN_DT)
trns$CANHX_END_DT = as.Date(trns$CANHX_END_DT)

# Only retain the common time-scale and same PX data:
trns = subset(trns, (CANHX_BEGIN_DT >= min(match$date) & (CANHX_BEGIN_DT <= max(match$date))))    # Because we can not count more waiting days and less 'offer' days!

# Comparing PX_IDs in both datasets:
uniqueN(match$PX_ID); uniqueN(trns$PX_ID)
com_PXs = intersect(unique(match$PX_ID), unique(trns$PX_ID))

trns = subset(trns, PX_ID %in% com_PXs)
match1 = subset(match, PX_ID %in% com_PXs)    # Therefore, only 'adult' patients should be there in match1, bcoz, trns has only 'adult' patients! : table(trns$pat_type)
match1 = match1[, c("DONOR_ID", "PX_ID", "MATCH_ID", "date", "CAN_OPO_CD", "CAN_OPO_REGION", "policy", "sharing", "PTR_STAT_CD_desp", "PTR_OFFER_ACPT")]

# Only Adult patients:      ## This chunk is Copied from "transition.Rmd" file: ##
trns = subset(trns, pat_type == "adult")
```

# Remove 'non-meaningful' offers and transitions, using 'offer acceptance date':
```{r}
pat_accept_date = match1[match1$PTR_OFFER_ACPT == "Y", c("PX_ID", "date")]
temp = data.table(pat_accept_date)[, list(cnt = .N), by = (PX_ID)]; nrow(temp[temp$cnt>1, ])/nrow(temp)   # 1053 patients out of 56109 (1.9%) accepted offers multiple times!
# Retain the latest date:
pat_accept_date = data.table(pat_accept_date)[, list(acpt_date = max(date)), by = (PX_ID)]

# Add the 'acpt_date' column:
match1 = merge(match1, pat_accept_date, all.x = T)
trns = merge(trns, pat_accept_date, all.x = T)

# Clean 'match1':
match1$flag = 0
match1$flag = match1$date - match1$acpt_date   # >0 is indicates 'offer' after already accepting an offer...thus remove these records
match1$flag = as.numeric(match1$flag); summary(match1$flag)
match2 = match1[((is.na(match1$flag)) | (as.numeric(match1$flag) <= 0)), ]

# Clean 'trns':
trns = trns[with(trns, order(PX_ID, CANHX_BEGIN_DT)), ]; row.names(trns) = c(1:nrow(trns))
summary(trns$time_period_wait)
trns[is.na(trns$time_period_wait), "time_period_wait"] = 0

trns1 = trns #[trns$PX_ID == 363115, ]

# Two cleaning steps, becoz in some cases, transitions happen even after acpt_date:
# 1. If 'CANHX_BEGIN_DT' > 'acpt_date', delete that record. After this, all records will have 'CANHX_BEGIN_DT' <= 'acpt_date'.
# 2. If 'CANHX_END_DT' > 'acpt_date', create a new column "CANHX_END_DT_Corrected" = "acpt_date", and modify the "time_period_wait" = 'acpt_date' - 'CANHX_BEGIN_DT' + 1

cond = !(!is.na(trns1$acpt_date) & (trns1$CANHX_BEGIN_DT > trns1$acpt_date))  # Step 1
trns1 = trns1[cond, ]
trns1$CANHX_END_DT_Corrected = NA
cond = (!is.na(trns1$acpt_date)) & (trns1$CANHX_END_DT >= trns1$acpt_date)   # Step 2: Only one record per PX_ID will be there with this cond
trns1$flag = as.numeric(trns1$CANHX_END_DT >= trns1$acpt_date)
cond = (!is.na(trns1$flag)) & (trns1$flag == 1)

# temp1 = temp[cond, ]
summary(trns1$time_period_wait)
trns1[cond, "time_period_wait"] = trns1[cond, "acpt_date"] - trns1[cond, "CANHX_BEGIN_DT"] + 1
summary(trns1$time_period_wait)
trns1 = trns1[, -c((ncol(trns1)-1):ncol(trns1))]

samp_match = subset(match1, PX_ID == 363261)
samp_trns = subset(trns1, PX_ID == 363261)
```


# Total days waiting at a MELD score ('time_period_adj' captures days spent in ONE state (CANHX_STAT_CD_desp)):
```{r}
trns1$policy = sapply(c(1:nrow(trns1)), function(i) {if (trns1$CANHX_BEGIN_DT[i] > "2013-06-17") {return ("post")} else {return ("pre")}})
table(trns1$policy)
trns11 = trns1[, c("PX_ID", "CAN_OPO_CD", "CAN_OPO_REGION", "CANHX_BEGIN_DT", "CANHX_END_DT", "MELD_col_desp", "nxt_MELD_col_desp", "time_period", "time_period_adj", "time_period_wait", "policy")]
trns11[, c("MELD_col_desp", "nxt_MELD_col_desp")] = lapply(trns11[, c("MELD_col_desp", "nxt_MELD_col_desp")], as.character)

unique(trns1$nxt_MELD_col_desp)

trns2 = data.table(trns11)[, list(tot_wait_time = sum(time_period_wait)), by = list(CAN_OPO_CD, CAN_OPO_REGION, policy, MELD_col_desp)]

# min(subset(trns1, policy == "post")$CANHX_BEGIN_DT)
```

# Write the files:
```{r}
if (state_agg == 1) {
  write.csv(trns2, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/", agg_level, "/pat_wait_time_", agg_level, "_", MELD_col_name, ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", ""), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)
  write.csv(match2, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/", agg_level, "/match_org_prob_", agg_level, "_", MELD_col_name, ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", ""), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)   # Only patients with CAN_AGE_IN_MONTHS_AT_LISTING >= 18*12
  } else {
  write.csv(trns2, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/pat_wait_time", "_", MELD_col_name, ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", ""), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)
  write.csv(match2, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/match_org_prob", "_", MELD_col_name, ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", ""), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)   # Only patients with CAN_AGE_IN_MONTHS_AT_LISTING >= 18*12
}

trns2 = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/", agg_level, "/", MELD_col_name, "/pat_wait_time_", agg_level, "_", MELD_col_name, ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", ""), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")))
match2 = read.csv(paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/", agg_level, "/", MELD_col_name, "/match_org_prob_", agg_level, "_", MELD_col_name, ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", ""), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")))

```

# Play with the BELOW chunks to create NEW ORGAN Classifications:

```{r}
don = don_src
shorten = 0   # i.e, Combine A3 and A4 to A34, Subsume CVA to 'Other'

# Age:
don$age_type = "A5" # DON_AGE >= 60
don[don$DON_AGE < 18, "age_type"] = "A1"
don[((don$DON_AGE >= 18) & (don$DON_AGE < 40)), "age_type"] = "A2"
don[((don$DON_AGE >= 40) & (don$DON_AGE < 50)), "age_type"] = "A3"
don[((don$DON_AGE >= 50) & (don$DON_AGE < 60)), "age_type"] = "A4"

# Race:
don$race_type = "Other" #don$DON_RACE_desp
don[don$DON_RACE_desp == "White", "race_type"] = "White"  # 'Hispanic' and 'Other' are clubbed into "Other".

# COD:
don$DON_CAD_DON_COD_desp = as.character(don$DON_CAD_DON_COD_desp); unique(don$DON_CAD_DON_COD_desp)
don$cod_type = don$DON_CAD_DON_COD_desp

don[(is.na(don$cod_type)), "cod_type"] = "Other"
don[(don$cod_type == "ANOXIA"), "cod_type"] = "Anoxia"
don[(don$cod_type == "CEREBROVASCULAR/STROKE"), "cod_type"] = "CVA"
don[((don$cod_type == "CNS TUMOR") | (don$cod_type == "HEAD TRAUMA") | (don$cod_type == "OTHER SPECIFY")), "cod_type"] = "Other"

# DCD:
don$dcd_type = "Yes"
don[is.na(don$DON_DCD_SUPPORT_WITHDRAW_TM), "dcd_type"] = "No"

# NO CLASSIFICATION:
if (SIMPLE == 1) {
  don$age_type = "no_type"    
  don$race_type = "no_type"
  don$cod_type = "no_type"
  don$dcd_type = "no_type"
} else if (shorten == 1) {
  # Adult donors only:
  # don = don[don$DON_AGE >= 18, ]
  don[((don$DON_AGE >= 40) & (don$DON_AGE < 60)), "age_type"] = "A34"
  don[(don$cod_type == "CVA"), "cod_type"] = "Other"
}

# Aggregate the types:
don$type = paste(don$age_type, don$race_type, don$cod_type, don$dcd_type, sep = "_")

# table(don$age_type)
# table(don$cod_type)
# table(don$type)
#plot(table(don$type))
unique(don$type)[1:4]; uniqueN(don$type)

# sum(is.na(don$type))
# lst1 = unique(match2$DONOR_ID)
# lst2 = unique(don$DONOR_ID)
```

# Only consider ADULT donors, and remove match records for pediatric donors:
```{r}
ped_donors = unique(don[don$DON_AGE < 18, "DONOR_ID"])
don = don[don$DON_AGE >= 18, ]
unique(don$age_type)

match2 = match2[!(match2$DONOR_ID %in% ped_donors), ]
```

Write the file:
```{r}
write.csv(don, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/donor_type_", uniqueN(don$type), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)
```

# Total offers at a MELD score:
```{r}
# min(don$date); max(don$date)
# uniqueN(don$DONOR_ID); uniqueN(match1$DONOR_ID)

# Import 'organ type' to the match file:
match2 = merge(match2, don[, c("DONOR_ID", "age_type", "race_type", "cod_type", "dcd_type", "type")], by = "DONOR_ID", all.x = T)
# temp = match2
if(sum(is.na(match2$type)) > 0) {print("SOMETHING WRONG!!!!")}

# Do we have common dates in match1 and trns11?
# min(trns1$CANHX_BEGIN_DT); max(trns1$CANHX_BEGIN_DT)
# match2$date = as.Date(match2$date)
# min(match2$date); max(match2$date)

# Total offers (Not aggregated by 'sharing'):
nrow(match2)
match2_ = match2
match2 = data.table(match2)[, list(tot_offers = .N, tot_pat_day_pairs = uniqueN(data.frame(PX_ID, date))), by = list(CAN_OPO_CD, CAN_OPO_REGION, policy, PTR_STAT_CD_desp, age_type, race_type, cod_type, dcd_type, type)] 
sum(match2$tot_offers); sum(match2$tot_pat_day_pairs)

unique(match2$PTR_STAT_CD_desp)
```

# To check if there are "offers" and "wait times" at ALL (MELD, DSA, policy):
```{r}
org_prob_agg = data.frame(DSA = NA, Region = NA, PTR_STAT_CD_desp = NA, policy = NA, tot_offers = NA, tot_wait_time = NA)

k = 1
for (DSA in unique(as.character(match2$CAN_OPO_CD))) {
  for (MELD in unique(as.character(trns2$MELD_col_desp))) {
    if (MELD != 'Temporarily Inactive') {
      for (policy in c('pre', 'post')) {
        cond1 = (match2$CAN_OPO_CD == DSA) & (match2$PTR_STAT_CD_desp == MELD) & (match2$policy == policy)
        cond2 = (trns2$CAN_OPO_CD == DSA) & (trns2$MELD_col_desp == MELD) & (trns2$policy == policy)
        # print (DSA)
        # print (MELD)
        org_prob_agg[k, c("DSA", "Region", "PTR_STAT_CD_desp", "policy")] = c(DSA, unique(match2[match2$CAN_OPO_CD == DSA, "CAN_OPO_REGION"]), MELD, policy)
        if (nrow(match2[cond1, ]) > 0) {
          org_prob_agg[k, c("tot_offers")] = sum(match2[cond1, "tot_offers"])
        }
        if (nrow(trns2[cond2, ]) > 0) {
          org_prob_agg[k, c("tot_wait_time")] = sum(trns2[cond2, "tot_wait_time"])
        }
        k = k + 1
      }
    }
  }
}
names(org_prob_agg)[which(colnames(org_prob_agg) %in% c("DSA", "Region"))] = c("CAN_OPO_CD", "CAN_OPO_REGION")
summary(org_prob_agg$tot_offers); sum(org_prob_agg$tot_offers, na.rm = T)
# org_prob_agg[(is.na(org_prob_agg$tot_pat_day_pairs) & !is.na(org_prob_agg$tot_wait_time)), "tot_pat_day_pairs"] = 0   # To make 'org_prob' when wait time is there but tot_pat_day_pairs, set tot_pat_day_pairs = 0!
org_prob_agg[(is.na(org_prob_agg$tot_offers) & !is.na(org_prob_agg$tot_wait_time)), "tot_offers"] = 0   # To make 'org_prob' when wait time is there but tot_offers, set tot_offers = 0!
org_prob_agg$org_prob = org_prob_agg$tot_offers / org_prob_agg$tot_wait_time

# Observations: 1. There are MELDs at which neither offers, nor wait times are observed, 2. There are MELDs at which wait times are there but no offer, 3. Fortunatey, there is no case where there is no wait time but offer is made.

# Fill those NA columns: There are 12 (MELD, DSA, policy) where no wait times are there:
org_prob_agg_NA = org_prob_agg[is.na(org_prob_agg$tot_wait_time), ]

Check file name:
write.csv(org_prob_agg, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/org_prob_agg_", agg_level, "_", uniqueN(don$type), ifelse(N_after_Y_filter == 1, "_NoN_after_Y_all_org.csv", "_all_org.csv")), row.names = F)
```

# Estimate 'organ offer probability':
```{r}
# 61*52*11/5*2 = 69784/31720 should be the size of 'org_prob', but not all organs are offered everywhere. Its okay to assumed 0 prob. of organ offer if (MELD, DSA, policy) has non-zero wait time.
# But in case when (MELD, DSA, policy) has zero wait time, then we can't say that prob. of organ offer = 0!! There are 12 such (MELD, DSA, policy) (see 'org_prob_agg_NA')

org_prob = merge(match2[, -"tot_pat_day_pairs"], trns2[trns2$MELD_col_desp != "Temporarily Inactive", ], by.x = c("CAN_OPO_CD", "CAN_OPO_REGION", "policy", "PTR_STAT_CD_desp"), by.y = c("CAN_OPO_CD", "CAN_OPO_REGION", "policy", "MELD_col_desp"), all = T)  # all, to include 6 cases with wait times but not offer; Since these 6 cases are not part of 'org_prob_agg_NA', so have to include then in 'org_prob'
org_prob[is.na(org_prob$tot_offers), "tot_offers"] = 0
sum(org_prob$tot_offers); sum(!is.na(org_prob$tot_wait_time)); nrow(match2)

# Have to fill something for these 12 (MELD, DSA, policy) cases, where neither offers, nor wait times are there.
# Sample from the highest likely organ type:
likely_org_type = data.frame(sort(table(don$type), decreasing = T)[1:4])
likely_org_type$p = likely_org_type$Freq / sum(likely_org_type$Freq)
likely_org_type$row_idx = c(1:nrow(likely_org_type))

if (nrow(org_prob_agg_NA) > 0) {
  org_prob = rbind(org_prob, org_prob_agg_NA[, c("CAN_OPO_CD", "policy", "PTR_STAT_CD_desp", "CAN_OPO_REGION")], fill = T)

  cond = is.na(org_prob$tot_wait_time)    # Identifies those 12 (MELD, DSA, policy) cases:
  org_prob[cond, c("tot_offers")] = 1
  # org_prob[cond, c("tot_pat_day_pairs")] = 1

  # Sample the organ types, because we need to assign some type to represent organ offer:
  lst = sample(likely_org_type$row_idx, size = nrow(org_prob_agg_NA), prob = likely_org_type$p, replace = T)
  org_prob[cond, c("type")] = as.character(likely_org_type$Var1[lst])
  org_prob[cond, c("tot_wait_time")] = round(1 / likely_org_type$p[lst], 0)

  for (i in c(1:nrow(org_prob))) {
    if (is.na(org_prob$age_type[i])) {
      val = strsplit(as.character(org_prob[i, "type"]), "_")[[1]]
      org_prob[i, c("age_type")] = val[1]; org_prob[i, c("race_type")] = val[2]; org_prob[i, c("cod_type")] = val[3]; org_prob[i, c("dcd_type")] = val[4]
    }
  }
}

# 'org_prob' is based on  "tot_offers", NOT "tot_pat_day_pairs"!!
org_prob$org_prob = org_prob$tot_offers / org_prob$tot_wait_time
```

# Rough:
```{r}
# Region-wise probability of organ offer:
temp = data.table(org_prob_agg)[, list(sum_tot_offers = sum(tot_offers), sum_tot_wait_time = sum(tot_wait_time)), by = list(CAN_OPO_REGION, policy, PTR_STAT_CD_desp)]
temp$org_prob = temp$sum_tot_offers / temp$sum_tot_wait_time

ggplot(data = subset(temp, temp$policy == "pre"), aes(x = CAN_OPO_REGION, y = org_prob, fill = PTR_STAT_CD_desp)) + 
  geom_bar(stat = "identity", position=position_dodge())
ggplot(data = subset(temp, temp$policy == "post"), aes(x = CAN_OPO_REGION, y = org_prob, fill = PTR_STAT_CD_desp)) + 
  geom_bar(stat = "identity", position=position_dodge())

m = lm(org_prob ~ PTR_STAT_CD_desp, subset(org_prob, (CAN_OPO_CD == "CAOP") & (policy == "pre")))
m = lm(org_prob ~ PTR_STAT_CD_desp, subset(temp, (policy == "pre")))
summary(m)   # Should increase with MELD.

# Rough:

temp = subset(org_prob, (PTR_STAT_CD_desp == "MELD/PELD 40") & (CAN_OPO_REGION == 3))
temp = data.table(temp)[, list(sum_tot_pat_day_pairs = sum(tot_pat_day_pairs), tot_wait_time = unique(tot_wait_time)), by = list(CAN_OPO_CD, policy)]
temp$prob = temp$sum_tot_pat_day_pairs/temp$tot_wait_time

temp = subset(trns1, CANHX_STAT_CD_desp == "MELD/PELD 40")
table(temp$nxt_CANHX_STAT_CD_desp)

samp = subset(match1, (CAN_OPO_CD == "OHLP") & (policy == "post") & (PTR_STAT_CD_desp == "MELD/PELD 39"))
samp_match = subset(match1, (CAN_OPO_CD == "OHLP") & (policy == "post") & (PX_ID == 1086152))   # 1046136
samp_match = subset(match, (PX_ID == 1250797))
samp_trns = subset(trns, (PX_ID == 1250797))
pats = unique(samp$PX_ID)

samp_match = subset(match1, (CAN_OPO_CD == "ALOB") & (policy == "pre")& (PTR_STAT_CD_desp == "Status 1") )
samp_trns = subset(trns1, (CAN_OPO_CD == "ALOB") & (policy == "pre")  & (CANHX_STAT_CD_desp == "Status 1"))

```


# Add a NEW organ type: "No organ offer", for each (DSA, MELD, policy):
```{r}
# Probability of "no_offer" in (DSA, MELD, policy): # 52*11 or 5*2 = 1144 or 520

## Approach 1:
# no_org_prob = org_prob_agg[, -which(colnames(org_prob_agg) == "org_prob")]
# no_org_prob$org_prob = 1 - org_prob_agg$org_prob     # Here, 'org_prob' refers to probability of "no_offer"!! 
# names(no_org_prob)[which(colnames(no_org_prob) %in% c("DSA", "Region"))] = c("CAN_OPO_CD", "CAN_OPO_REGION")

no_org_prob = data.table(org_prob)[, list(tot_wait_time = unique(tot_wait_time), org_prob = max((1 - sum(tot_offers)/ unique(tot_wait_time)), 0)), by = list(CAN_OPO_CD, CAN_OPO_REGION, policy, PTR_STAT_CD_desp)]
summary(no_org_prob$org_prob)
```

```{r}
## Approach 2: Treat 'no_offer' as a type of 'organ_type', and thus calculate the # of days with no_offer, and divide by total waiting time:
approach2 = 1

if (approach2 == 1) {
  temp = data.table(match2_)[, list(tot_offers = .N, tot_pat_day_pairs_any_org = uniqueN(data.frame(PX_ID, date))), by = list(CAN_OPO_CD, CAN_OPO_REGION, policy, PTR_STAT_CD_desp)] 
  sum(temp$tot_offers); sum(temp$tot_pat_day_pairs_any_org)     # tot_offers > tot_pat_day_pairs_any_org, because of multiple offers in a day!
  temp = temp[, -"tot_offers"]
  
  temp = merge(temp, unique(org_prob[, c("CAN_OPO_CD", "CAN_OPO_REGION", "policy", "PTR_STAT_CD_desp", "tot_wait_time")]), by = c("CAN_OPO_CD", "CAN_OPO_REGION", "policy", "PTR_STAT_CD_desp"))
  temp$any_org_prob = temp$tot_pat_day_pairs_any_org / temp$tot_wait_time   # Probability of getting at least one offer in a day = 1 - Prob. of no_offer
  
  m = lm(any_org_prob ~ PTR_STAT_CD_desp, temp); summary(m)
  
  # temp$PTR_STAT_CD_desp = as.character(temp$PTR_STAT_CD_desp)
  # no_org_prob$PTR_STAT_CD_desp = as.character(no_org_prob$PTR_STAT_CD_desp)
  temp1 = setdiff(unique(no_org_prob[, -c(5, 6)]), unique(temp[, -c(5, 6, 7)]))   # This is because, no offers were made for these 4 combinations, thus no 'any_org_prob'.
  if (nrow(temp1) > 0) {
    temp1 = merge(temp1, no_org_prob, all.x = T)
  }
  
  temp$org_prob = 1 - temp$any_org_prob
  if (nrow(temp1) > 0) {
    no_org_prob = rbind(within(temp, rm("tot_pat_day_pairs_any_org", "any_org_prob")), temp1)
  } else {
    no_org_prob = temp[, -c("tot_pat_day_pairs_any_org", "any_org_prob")]
  }
  
  summary(no_org_prob$org_prob)
}
```

```{r}
org_prob = as.data.frame(org_prob)

org_p_com = rbind(org_prob[org_prob$tot_offers > 0, ], no_org_prob, fill = T)     # nrow(org_prob) + nrow(no_org_prob) - 6; -6 to not double count 6 cases with wait times but not offer.
org_p_com[is.na(org_p_com$type), "type"] = "no_offer"
org_p_com = as.data.frame(org_p_com)

temp = subset(org_p_com, (org_p_com$type == "no_offer")); summary(temp$org_prob)
uniqueN(temp[, c("CAN_OPO_CD", "policy", "PTR_STAT_CD_desp")])
```

# Write the file:
```{r}
# samp = subset(org_p_com, (CAN_OPO_CD == "CAOP") & (PTR_STAT_CD_desp == "MELD/PELD 15-24") & (policy == "pre"))
temp = data.table(org_p_com)[, list(cnt_no_offer = sum(is.na(dcd_type))), by = list(CAN_OPO_CD, policy, PTR_STAT_CD_desp)]
if (max(temp$cnt_no_offer) != 1) {print("SOMETHING WRONG!!!!")}

if(approach2 == 1) {
  write.csv(org_p_com, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/", agg_level, "/org_prob_com_", agg_level, "_", MELD_col_name, uniqueN(don$type), ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", "_all_offers_aprch2"), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)
} else {
  if(state_agg == 1) {
    write.csv(org_p_com, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/", agg_level, "/org_prob_com_", agg_level, "_", MELD_col_name, uniqueN(don$type), ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", "_all_offers"), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)
  } else {
    write.csv(org_p_com, paste0("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/Transition_matrix/org_prob_com", "_", MELD_col_name, unique(don$type), ifelse(del_multi_offers_in_a_day == 1, "_del_multi_offers", "_all_offers"), ifelse(N_after_Y_filter == 1, "_NoN_after_Y.csv", ".csv")), row.names = F)
    }
  }
  
```

# Some summary charts:
```{r}


```










