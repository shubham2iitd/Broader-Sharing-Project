
```{r}
library(data.table)
library(readxl)
library(openxlsx)
library(ggplot2)
library(maptools)
library(foreign)
library(plyr)
library(haven)
```

Match Analysis:
```{r}
we don't know what centers were actually offered the organs that were "eventually discarded" - the file says decline for every candidate but in reality the OPO stopped calling people at some point and we don't know where that is.

match = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/ptr_li_10_18_Nov1_42col.csv")
names(match)
table(match$PTR_OFFER_ACPT)

match$date = as.Date(match$MATCH_SUBMIT_DT, format= "%Y-%m-%d")
```

```{r}
table(match$PTR_ORG_PLACED)
table(match$PTR_OFFER_ACPT)
```


```{r}
temp = data.table(match)[, list(MATCH_ID_cnt = uniqueN(MATCH_ID)), by = DONOR_ID]
max(temp$MATCH_ID_cnt)
table(temp$MATCH_ID_cnt)/nrow(temp)

lst = c(temp[temp$MATCH_ID_cnt > 1, 'DONOR_ID'])$DONOR_ID
match_many = match[match$DONOR_ID %in% lst, ]
```

```{r}
# Exploring the DONOR_IDs with >1 MATCH_IDs:

temp = data.table(match_many)[, list(MATCH_ID_cnt = uniqueN(MATCH_ID), cnt = .N,max_PTR_seq = max(PTR_SEQUENCE_NUM), cnt_PX = uniqueN(PX_ID), cnt_accpt = sum(PTR_OFFER_ACPT == "Y")), by = DONOR_ID]

summary(temp)
table(temp$cnt_accpt)

lst1 = c(temp[temp$cnt_accpt > 1, 'DONOR_ID'])$DONOR_ID
temp1 = match_many[match_many$DONOR_ID %in% lst1, ]
temp1 = temp1[with(temp1, order(MATCH_ID, PTR_SEQUENCE_NUM)), ]
table(temp1$PTR_ORG_PLACED)
min(temp1$date); max(temp1$date)
```

```{r}
table(match[match$MATCH_cnt_Y == 0, "PTR_OFFER_ACPT"])
table(match[match$DONOR_cnt_Y == 0, "PTR_OFFER_ACPT"])
```

```{r}
max(match$MATCH_cnt_Y)
table(match[match$MATCH_cnt_Y == 2, "PTR_ORG_PLACED"])    # Consists of "LI-S" only!

samp_match = match[match$MATCH_ID == "586202", ]
unique(samp_match$PTR_ORG_PLACED)
```

# Below chunk for removing rows when "PTR_OFFER_ACPT" = B or NA:
```{r}
# match after "DELETING" BYPASS rows!
match$PTR_OFFER_ACPT = as.character(match$PTR_OFFER_ACPT)
table(match$PTR_OFFER_ACPT)
match_not_B = match[!(match$PTR_OFFER_ACPT == "B"), ]

# No. of MATCH_IDs with 1 Y:
temp = data.table(match_not_B)[, list(cnt_Y = sum(PTR_OFFER_ACPT == "Y")), by = MATCH_ID]
table(temp$cnt_Y)   # 0: 23216, 1: 61112, 2: 594

unique(match_not_B$PTR_OFFER_ACPT); sum(match_not_B$PTR_OFFER_ACPT == "")

# Function to count the # NAs before "Y" decision:
f = function(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, cnt_Y) {
  df = data.frame(col1 = PTR_SEQUENCE_NUM, col2 = PTR_OFFER_ACPT)
  df = df[with(df, order(PTR_SEQUENCE_NUM)), ]
  Y_seq = df[df[, 2] == "Y", 1]
  if (length(Y_seq) == cnt_Y) {
    temp = df[df[, 1] <= max(Y_seq), ]
    return (nrow(temp[temp$col2 == "", ]))
  }
}

f(samp_match$PTR_SEQUENCE_NUM, samp_match$PTR_OFFER_ACPT, 1)

# Only considering MATCH_IDs with 1 "Y":
temp2 = data.table(match_not_B[match_not_B$MATCH_cnt_Y == 1, ])[, list(cnt_NA = length(!is.na(PTR_OFFER_ACPT)), NA_before_Y = f(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, 1)), by = MATCH_ID] # 594 MATCH_IDs have 2 "Y"s.
table(temp2$NA_before_Y)
# Since the values are "NA" or 0, we can safely assume that for "MATCH_IDs" resulting in "LI-W" (or, # Y = 1 for a MATCH_ID), the column values in "PTR_OFFER_ACPT" are NOT "NA" until PTR_OFFER_ACPT == "Y"!, Therefore, we can DELETE "NA" rows for "LI-W" category, because they are UN-INFORMATIVE!  
# We can also delete "NA" rows for (# Y = 0 for a MATCH_ID), because no offers were accepted eventually!, and "NA" are UN-INFORMATIVE!

# Only considering MATCH_IDs with 2 "Y":
samp_match[samp_match[, "PTR_OFFER_ACPT"] == "Y", "PTR_SEQUENCE_NUM"]
temp = data.table(match_not_B[match_not_B$MATCH_cnt_Y == 2, ])[, list(cnt_NA = length(!is.na(PTR_OFFER_ACPT)), NA_before_Y = f(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, 2)), by = MATCH_ID] # 594 MATCH_IDs have 2 "Y"s.
table(temp$NA_before_Y)
# Since the values are "NA" or 0, we can safely assume that for "MATCH_IDs" resulting in "LI-S" (or, # Y = 2 for a MATCH_ID), the column values in "PTR_OFFER_ACPT" are NOT "NA" until 2nd PTR_OFFER_ACPT == "Y"!, Therefore, we can DELETE "NA" rows for "LI-S" category, because they are UN-INFORMATIVE!  

# DELETE rows with NA in "PTR_OFFER_ACPT":
table(match_not_B$PTR_OFFER_ACPT)
match_not_B_NA = match_not_B[!(match_not_B$PTR_OFFER_ACPT == ""), ]
```

Write the files:

```{r}
write.csv(match_not_B_NA, "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA.csv", row.names = F)
write.csv(match[!(match$PTR_OFFER_ACPT == ""), ], "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_NA.csv", row.names = F)
```

```{r}
# To check if there is only ONE sequence of "PTR_SEQUENCE_NUM" for every MATCH_ID: (by counting the # of 1:)
# NOTE: There are MATCH_IDs (e.g. 727922) where "PTR_OFFER_ACPT" have values Z or N after Y, although the "PTR_ORG_PLACED" = LI-W for the Y and only 1 Y!
f1 = function(lst) {
  lst = lst[lst == 1]
  return(length(lst))
}
temp = data.table(match[!(match$PTR_OFFER_ACPT == ""), ])[, list(cnt_1 = f1(PTR_SEQUENCE_NUM)), by = MATCH_ID]
table(temp$cnt_1)

temp2 = data.table(match)[, list(cnt_1 = f1(PTR_SEQUENCE_NUM)), by = MATCH_ID]
table(temp2$cnt_1)  # The MATCH_IDs (eg. 1076020) for 2 ones have duplicate rows with 'PTR_SEQUENCE_NUM'=1, except "PTR_OFFER_ID"

samp_match = match_not_B_NA[match_not_B_NA$MATCH_ID == "586202", ]
samp_match = match[match$MATCH_ID == "581650", ]
```

```{r}
table(match_not_B_NA$MATCH_PTR_ORG_PLACED_type)
table(match_not_B_NA$PTR_ORG_PLACED) / uniqueN(match_not_B_NA$MATCH_ID)
nrow(match_not_B_NA) / uniqueN(match_not_B_NA$MATCH_ID)
```

# Remove "Z" (Provisional Yes) from the data:
```{r}
# Are there any "Z" before "Y"?
# Function to count the #Z before "Y" decision:
f = function(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, cnt_Y) {
  df = data.frame(col1 = PTR_SEQUENCE_NUM, col2 = PTR_OFFER_ACPT)
  df = df[with(df, order(PTR_SEQUENCE_NUM)), ]
  Y_seq = df[df[, 2] == "Y", 1]
  if (length(Y_seq) == cnt_Y) {
    temp = df[df[, 1] <= max(Y_seq), ]
    return (nrow(temp[temp$col2 == "Z", ]))
  }
}

f(samp_match$PTR_SEQUENCE_NUM, samp_match$PTR_OFFER_ACPT, 1)

# Only considering MATCH_IDs with 1 "Y":
temp2 = data.table(match_not_B_NA[match_not_B_NA$MATCH_cnt_Y == 1, ])[, list(cnt_NA = length(!is.na(PTR_OFFER_ACPT)), Z_before_Y = f(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, 1)), by = MATCH_ID] # 594 MATCH_IDs have 2 "Y"s.
max(temp2$Z_before_Y)

# Only considering MATCH_IDs with 2 "Y":
temp = data.table(match_not_B_NA[match_not_B_NA$MATCH_cnt_Y == 2, ])[, list(cnt_NA = length(!is.na(PTR_OFFER_ACPT)), Z_before_Y = f(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, 2)), by = MATCH_ID] # 594 MATCH_IDs have 2 "Y"s.
max(temp$Z_before_Y)

# Since there are NO "Z" before "Y", its safe to delete "Z" from the data....DELETE rows with "Z" in "PTR_OFFER_ACPT":
table(match_not_B_NA$PTR_OFFER_ACPT)
match_not_B_NA_Z = match_not_B_NA[!(match_not_B_NA$PTR_OFFER_ACPT == "Z"), ]
#table(match_not_B_NA_Z$PTR_OFFER_ACPT)
```

# Remove (initial) MATCH_IDs for which the subsequent MATCH_ID was created within 2 hrs! (Indicating update in organ characteristics):
# Note that "to be removed MATCH_IDs" should NOT have resulted in 'ACCEPTANCE'.
```{r}
temp = data.table(match_not_B_NA_Z)[, list(cnt_MATCH_IDs = uniqueN(MATCH_ID)), by = DONOR_ID]
table(temp$cnt_MATCH_IDs)
temp = merge(temp[temp$cnt_MATCH_IDs >= 2, ], unique(match_not_B_NA_Z[, c("DONOR_ID", "MATCH_ID", "MATCH_SUBMIT_DT")]))
temp = temp[order(temp$DONOR_ID, temp$MATCH_ID), ]

# DONOR_IDs with 2 MATCH_IDs:
temp2 = data.table(temp[temp$cnt_MATCH_IDs == 2, ])[, list(time_diff = difftime(MATCH_SUBMIT_DT[2], MATCH_SUBMIT_DT[1], units = "hours")), by = DONOR_ID]

# Remove the first MATCH_ID for the DONOR_IDs whose 'time_diff' < 2 hrs!
rem_MATCH_IDs = data.table(temp[temp$DONOR_ID %in% subset(temp2, time_diff < 2)$DONOR_ID, ])[, list(rem_MATCH_ID = MATCH_ID[1]), by = DONOR_ID]$rem_MATCH_ID

# Make sure to NOT remove "MATCH_IDs" that have MATCH_cnt_Y > 0
temp3 = data.table(match_not_B_NA_Z[match_not_B_NA_Z$MATCH_ID %in% rem_MATCH_IDs, ])[, list(cnt_Y = sum(PTR_OFFER_ACPT == "Y")), by = MATCH_ID]

rem_MATCH_IDs = temp3[temp3$cnt_Y == 0, ]$MATCH_ID    # 387 MATCH_IDs remain out of 474!

# DONOR_IDs with 3 MATCH_IDs:  
temp = temp[order(temp$DONOR_ID, temp$MATCH_ID), ]
temp2 = data.table(temp[temp$cnt_MATCH_IDs == 3, ])[, list(time_diff1 = difftime(MATCH_SUBMIT_DT[2], MATCH_SUBMIT_DT[1], units = "hours"), 
                                                           time_diff2 = difftime(MATCH_SUBMIT_DT[3], MATCH_SUBMIT_DT[2], units = "hours")), by = DONOR_ID]

rem_MATCH_IDs_2 = c()    # Only consider "time_diff1" becoz the 3rd MATCH might have run <2 hrs for a reason other than donor info update.
for (i in c(1:nrow(temp2))) {
  if (temp2$time_diff1[i] < 2) {
    don = temp2$DONOR_ID[i]
    rem_MATCH_IDs_2 = c(rem_MATCH_IDs_2, as.numeric(temp[temp$DONOR_ID == don, "MATCH_ID"][1]))
  }
  if (temp2$time_diff2[i] < 2) {
    #don = temp2$DONOR_ID[i]; rem_MATCH_IDs_2 = c(rem_MATCH_IDs_2, as.numeric(temp[temp$DONOR_ID == don, "MATCH_ID"][2]))
  }
}
temp3 = data.table(match_not_B_NA_Z[match_not_B_NA_Z$MATCH_ID %in% rem_MATCH_IDs_2, ])[, list(cnt_Y = sum(PTR_OFFER_ACPT == "Y")), by = MATCH_ID]
rem_MATCH_IDs_2 = temp3[temp3$cnt_Y == 0, ]$MATCH_ID    # 387 MATCH_IDs remain out of 474!


# Remove these MATCH_IDs from the data:
match_not_B_NA_Z_2hrs = subset(match_not_B_NA_Z, !(MATCH_ID %in% c(rem_MATCH_IDs, rem_MATCH_IDs_2)))
```

# Remove duplicate PX_IDs for the same DONOR_ID:
```{r}
library(dplyr)
temp = data.table(match_not_B_NA_Z_2hrs)[, list(cnt_PX = .N, cnt_Y = sum(PTR_OFFER_ACPT == "Y"), cnt_MATCH_IDs = uniqueN(MATCH_ID)), by = list(DONOR_ID, PX_ID)]
table(temp$cnt_PX); table(temp$cnt_Y)   # So, there are 1072 (DONOR_ID, PX_ID) pairs that said "Y" twice!!...Assuming that two 'Y' were in two MATCH_IDs.
# samp_match = subset(match_not_B_NA_Z_2hrs, DONOR_ID == 545877)

table(match_not_B_NA_Z_2hrs$PTR_OFFER_ACPT)    # After duplicate removals, 'Y' should be 61056 ((DONOR_ID, PX_ID) that accepted once) + 1072 ((DONOR_ID, PX_ID) that accepted twice) = 61228

match_not_B_NA_Z_2hrs$DONOR_ID_PX_ID = paste(match_not_B_NA_Z_2hrs$DONOR_ID, match_not_B_NA_Z_2hrs$PX_ID, sep = "_")
match_not_B_NA_Z_2hrs$Y = 0; match_not_B_NA_Z_2hrs[match_not_B_NA_Z_2hrs$PTR_OFFER_ACPT == "Y", "Y"] = 1; table(match_not_B_NA_Z_2hrs$Y)
match_not_B_NA_Z_2hrs = distinct(match_not_B_NA_Z_2hrs[order(match_not_B_NA_Z_2hrs$DONOR_ID_PX_ID, -match_not_B_NA_Z_2hrs$Y), ], DONOR_ID_PX_ID, .keep_all = T)
match_not_B_NA_Z_2hrs = match_not_B_NA_Z_2hrs[, -c(ncol(match_not_B_NA_Z_2hrs)-1, ncol(match_not_B_NA_Z_2hrs))]
```

# Write the file:
```{r}
write.csv(match_not_B_NA_Z_2hrs, "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA_Z_2hrs.csv", row.names = F)
```

# Remove records of organs that were eventually DISCARDED: 
```{r}
temp = data.table(match_not_B_NA_Z_2hrs)[, list(cnt_acpt = sum(PTR_OFFER_ACPT == "Y")), by = DONOR_ID]
table(temp$cnt_acpt)

match_not_B_NA_Z_2hrs_ACPT = match_not_B_NA_Z_2hrs[match_not_B_NA_Z_2hrs$DONOR_ID %in% temp[temp$cnt_acpt >= 1, ]$DONOR_ID, ]
```

# Now, recalculate "PTR_SEQUENCE_NUM" (because BYPASSED, B should NOT be considered, and luckily NA rows were after Y) in a new column: "PTR_SEQUENCE_NUM_upd"
```{r}
# Writing the SEQUENCE_NUM of the First/Second Y:
f2 = function(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, pos) {    # pos can be only 1 or 2, since maximum nos. of Y is 2 for a MATCH_ID!
  df = data.frame(col1 = PTR_SEQUENCE_NUM, col2 = PTR_OFFER_ACPT)
  df = df[with(df, order(PTR_SEQUENCE_NUM)), ]
  Y_seq = df[df[, 2] == "Y", 1]
  if (length(Y_seq) > 0) {
    if (pos == 1) {   # i.e. First Y's sequence No
      val1 = uniqueN(df[df$col1 <= min(Y_seq), ]$col1)
      return (val1)
    } else if (pos == 2) {    # i.e. Second Y's sequence No
      if (length(Y_seq) == 2) {
        val2 = uniqueN(df[df$col1 <= max(Y_seq), ]$col1)
        return (val2)
      } else {return (integer())}
    }
  } else {return (integer())}
}

temp = data.table(match_not_B_NA_Z_2hrs_ACPT)[, list(MATCH_seq_Y1 = f2(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, pos = 1), MATCH_seq_Y2 = f2(PTR_SEQUENCE_NUM, PTR_OFFER_ACPT, pos = 2)), by = MATCH_ID]
summary(temp$MATCH_seq_Y1)
summary(temp$MATCH_seq_Y2)

samp_match = match[match$MATCH_ID == "675675", ]
```

# Write the file:
```{r}
write.csv(temp, "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/MATCH_seq_Y.csv", row.names = F)

# Merge:
match_not_B_NA_Z_2hrs_ACPT = merge(match_not_B_NA_Z_2hrs_ACPT, temp, by = "MATCH_ID", all.x = T)
```

```{r}
# Summary of Y_seq:
cond = (match_not_B_NA_Z_2hrs_ACPT$PTR_OFFER_ACPT == "Y")
match_y1_sum = data.table(match_not_B_NA_Z_2hrs_ACPT[cond, ])[, list(count_Y = .N, SEQ_quantile_25_Y = quantile(MATCH_seq_Y1)[2], SEQ_median_Y = quantile(MATCH_seq_Y1)[3], SEQ_quantile_75_Y = quantile(MATCH_seq_Y1)[4], SEQ_mean_Y = mean(MATCH_seq_Y1)), by = list(MATCH_OPO_CTR_CD, MATCH_OPO_REGION, policy)]

# THERE ARE SOME OUTLIERS WITH VERY HIGH SEQUENCE NUMBER THAT CAN INCREASE THE MEAN!!

write.xlsx(match_y1_sum, "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_y1_sum_29Aug.xlsx", sheetName="29Aug")
```

# Recalculate "PTR_SEQUENCE_NUM" and store in "PTR_SEQUENCE_NUM_upd"
```{r}
names(match_not_B_NA_Z_2hrs_ACPT)

samp_match = match_not_B_NA_Z_2hrs_ACPT[match_not_B_NA_Z_2hrs_ACPT$MATCH_ID == 1076020, ]

match_not_B_NA_Z_2hrs_ACPT = data.table(match_not_B_NA_Z_2hrs_ACPT)[order(PTR_SEQUENCE_NUM),  PTR_SEQUENCE_NUM_upd:= rleid(PTR_SEQUENCE_NUM), by = c("MATCH_ID")]

mean(match_not_B_NA_Z_2hrs_ACPT$PTR_SEQUENCE_NUM); mean(match_not_B_NA_Z_2hrs_ACPT$PTR_SEQUENCE_NUM_upd)
```

# Create a column to indicate "N" after "Y":
```{r}
table(match_not_B_NA_Z_2hrs_ACPT$PTR_OFFER_ACPT)
#temp = match_not_B_NA_Z_2hrs_ACPT

f = function (PTR_SEQUENCE_NUM_upd, PTR_OFFER_ACPT) {
  df = data.frame(col1 = PTR_SEQUENCE_NUM_upd, col2 = PTR_OFFER_ACPT)
  df = df[order(df[, 1]), ]
  Y_SEQ = df[df[, 2] == "Y", 1]
  if (length(Y_SEQ) > 0) {
    col3 = rep(1, nrow(df))
    col3[1:(max(Y_SEQ))] = 0
  } else {col3 = rep(0, nrow(df))}
  return (col3)
}

samp_match = subset(match_not_B_NA_Z_2hrs_ACPT, MATCH_ID == 581650)    # 1076020
samp_match[2, "PTR_OFFER_ACPT"] = "Y"
f(samp_match$PTR_SEQUENCE_NUM_upd, samp_match$PTR_OFFER_ACPT)

match_not_B_NA_Z_2hrs_ACPT = data.table(match_not_B_NA_Z_2hrs_ACPT[order(match_not_B_NA_Z_2hrs_ACPT$PTR_SEQUENCE_NUM_upd), ])[, N_after_Y := f(PTR_SEQUENCE_NUM_upd, PTR_OFFER_ACPT), by = MATCH_ID]
  
```

Write the file:
```{r}
write.csv(match_not_B_NA_Z_2hrs_ACPT, "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA_Z_2hrs_ACPT_MATCH_seq_PTR_upd_N_after_Y.csv", row.names = F)   # "MATCH_seq" already done!

# df = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA_Z_2hrs_ACPT_MATCH_seq_PTR_upd_N_after_Y.csv")   # 2424539
```

# Add "Blood type" of Donor+Patients, and 'sharing' type:
```{r}
df = match_not_B_NA_Z_2hrs_ACPT

# Find the DSA of PX_id, and classify the offer as local/regional/national:

wl = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/waitlist.csv")
tx = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/tx.csv")
don = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/donor.csv")

# Vlookup CANDIDATE's information using PX_ID:
wl1 = wl[, c("PX_ID", "CAN_SOURCE", "CAN_ABO", "CAN_ACPT_A2_DON", "CAN_ACPT_ABO_INCOMP", "CAN_ACPT_EXTRACORP_LI", "CAN_ACPT_HBC_POS", "CAN_ACPT_HCV_POS", "CAN_AGE_IN_MONTHS_AT_LISTING", "CAN_GENDER", "CAN_MOST_RECENT_HGT_CM", "CAN_MOST_RECENT_WGT_KG", "CAN_OPO_CD", "CAN_OPO_REGION", "CAN_CTR_CD", "CAN_LIVING_DON_TX", "CAN_MAX_AGE", "CAN_MAX_MILE", "CAN_MAX_WGT")]

tx1 = tx[, c(intersect(names(wl1), names(tx)), "CAN_WGT_KG", "REC_OPO_CD", "REC_OPO_REGION", "REC_CTR_CD")]
names(tx1)[6:9] = c("CAN_MOST_RECENT_WGT_KG", "CAN_OPO_CD", "CAN_OPO_REGION", "CAN_CTR_CD")

# Are there any PX_ID in tx that were not found in wl:
uniqueN(c(wl$PX_ID, tx$PX_ID)) - uniqueN(wl$PX_ID)  # 248 new PX_IDs in tx:
tx1 = subset(tx1, PX_ID %in% setdiff(union(wl$PX_ID, tx$PX_ID), wl$PX_ID))

wl1_com = dplyr::bind_rows(wl1, tx1)

# Add CAN info to match file:
intersect(names(df), names(wl1_com))
df_can = merge(df, wl1_com, by = "PX_ID", all.x = T)

nrow(df_can[(is.na(df_can$CAN_OPO_CD)), ]) / nrow(df_can)  # 1.76 % records do not have PX_ID in wl1_com!
uniqueN(subset(df_can, is.na(CAN_OPO_CD))$MATCH_ID); uniqueN(subset(df_can, is.na(CAN_OPO_CD))$PX_ID)
```

# Adding "DONOR" info in a similar way:
```{r}
names(don)
names(df)
intersect(names(don), names(df))
don1 = don[, c("DONOR_ID", "DON_ABO", "DON_AGE_IN_MONTHS", "DON_GENDER", "DON_CAD_DON_COD", "DON_COD_DON_STROKE", "DON_DEATH_MECH", "DON_WGT_KG", "DON_OPO_CTR_CD", "DON_OPO_REGION", "DON_ORG", "DON_TX_CTR_ID", "DON_DISCARD_CD", "DON_DISPOSITION", "DON_REASON_CD")]

# # Are there any DONOR_ID in match that were not found in don:
# uniqueN(c(don1$DONOR_ID, df_can$DONOR_ID)) - uniqueN(df_can$DONOR_ID)  # 7139 new DONOR_IDs not found!, out of 75795!
# uniqueN(df_can$DONOR_ID)

tx2 = tx[, c(intersect(names(don1), names(tx)), "DON_OPO_CD")]

# Are there any DONOR_ID in tx that were not found in don1:
uniqueN(c(don1$DONOR_ID, tx2$DONOR_ID)) - uniqueN(don1$DONOR_ID)  # 2853 new DONOR_IDs in tx:
tx2 = subset(tx2, DONOR_ID %in% setdiff(union(don1$DONOR_ID, tx2$DONOR_ID), don1$DONOR_ID))

don1_com = dplyr::bind_rows(don1, tx2)

# Add DONOR info to match file:
intersect(names(df), names(don1_com))
df_can_don = merge(df_can, don1_com, by = "DONOR_ID", all.x = T)

nrow(df_can_don[(is.na(df_can_don$DON_OPO_CD)), ]) / nrow(df_can_don)  # 100% becoz, don1_com does not have info on "DON_OPO_CD", expet 2 records
uniqueN(subset(df_can_don, is.na(DON_OPO_CD))$MATCH_ID); uniqueN(subset(df_can_don, is.na(CAN_OPO_CD))$DONOR_ID)
```

# Add sharing column:
```{r}
#df_can_don = subset(df_can_don, !is.na(CAN_OPO_CD))

df_can_don %>% mutate_if(is.factor, as.character) -> df_can_don

df_can_don$sharing = ""
df_can_don[(!is.na(df_can_don$CAN_OPO_CD)) & (df_can_don$MATCH_OPO_CTR_CD == df_can_don$CAN_OPO_CD), "sharing"] = "local"
df_can_don[(!is.na(df_can_don$CAN_OPO_CD)) & (df_can_don$sharing != "local") & (df_can_don$MATCH_OPO_REGION == df_can_don$CAN_OPO_REGION), "sharing"] = "regional"
df_can_don[(!is.na(df_can_don$CAN_OPO_CD)) & (df_can_don$sharing == "") & (df_can_don$MATCH_OPO_REGION != df_can_don$CAN_OPO_REGION), "sharing"] = "national"

table(df_can_don$sharing)  # 41809 recods do not have CAN_OPO_CD (since PX_ID not found in wl1_com)
```

```{r}
lst = c("CAN_ABO", "DON_ABO", "PTR_TXC_REFUSAL_VERIFY", "PTR_CHG_PROCESS_CD")
for (col in lst) {
  df_can_don[, col] = as.character(df_can_don[, col])
  df_can_don[, col] = gsub("b'", "", df_can_don[, col])
  df_can_don[, col] = gsub("'", "", df_can_don[, col])
}

table(df_can_don$PTR_CHG_PROCESS_CD)

samp_match = df_can_don[4506:5000, ]
```

# Write the file (FINAL):
```{r}
write.csv(df_can_don, "/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA_Z_2hrs_ACPT_MATCH_seq_PTR_upd_N_after_Y_CAN_DON_info.csv", row.names = F)

#df = read.csv("/Volumes/GoogleDrive/My Drive/SRTR/Analysis/match_not_B_NA_Z_2hrs_ACPT_MATCH_seq_PTR_upd_N_after_Y_CAN_DON_info.csv")
```

#
#
#

```{r}
hist(match_not_B_NA$PTR_SEQUENCE_NUM_upd, breaks = length(c(1:1000)), freq = F, xlim = c(1, 300))
temp = data.table(match_not_B_NA)[, list(.N)]
```

```{r}
rem_MELD = c("MELD/PELD -1", "MELD/PELD -2", "MELD/PELD -3", "MELD/PELD -4", "MELD/PELD -5", "MELD/PELD -6", "MELD/PELD -7", "MELD/PELD -8", "MELD/PELD -9", "MELD/PELD -10", "MELD/PELD -11", "MELD/PELD -12", "MELD/PELD 0", "MELD/PELD 1", "MELD/PELD 2", "MELD/PELD 3", "MELD/PELD 4", "MELD/PELD 5", "Status 2A", "Status 2B", "Status 3", "Temporarily Inactive", "Old status 2", "Old status 4")

temp1 = match_not_B_NA_MATCH_seq[!(match_not_B_NA_MATCH_seq$PTR_STAT_CD_desp %in% rem_MELD), ]
unique(temp1$PTR_STAT_CD_desp)

#temp1$MELD = MELD_mod(as.character(temp1$PTR_STAT_CD_desp))
temp1$MELD = sapply(as.character(temp1$PTR_STAT_CD_desp), function(x) {MELD_mod(x)})


# Average MELD by position:
cond1 = (temp1$policy == "pre")
temp = data.table(temp1)[, list(cnt = .N, avg_MELD = mean(MELD)), by = list(PTR_SEQUENCE_NUM_upd, yr)]
plot(temp$PTR_SEQUENCE_NUM_upd, temp$avg_MELD, xlim = c(1, 100), xlab = "Position on offer list", ylab = "avg_MELD at the position")

plot(temp[(temp$policy == "pre"), ]$PTR_SEQUENCE_NUM_upd, temp[(temp$policy == "pre"), ]$avg_MELD, col="red",  xlim = c(1, 100), ylim = c(5, 40) )
par(new=TRUE)
plot(temp[!(temp$policy == "pre"), ]$PTR_SEQUENCE_NUM_upd, temp[!(temp$policy == "pre"), ]$avg_MELD, col="green",  xlim = c(1, 100), ylim = c(5, 40))

g <- ggplot(temp, aes())
g <- g + geom_line(aes(y=y1), colour="red")
g <- g + geom_line(aes(y=y2), colour="green")
g

ggplot(temp[temp$PTR_SEQUENCE_NUM_upd < 100, ], aes(x = PTR_SEQUENCE_NUM_upd, y = avg_MELD)) + geom_point() + facet_wrap(~policy)

cond = (temp$PTR_SEQUENCE_NUM_upd < 100)
# ggplot() +
#   geom_line(temp[(temp$policy == "pre") & cond, ], mapping = aes(x = PTR_SEQUENCE_NUM_upd, y = avg_MELD, colour = "pre")) + 
#   geom_line(temp[(temp$policy == "post") & cond, ], mapping = aes(x = PTR_SEQUENCE_NUM_upd, y = avg_MELD, colour = "post")) +
#   scale_colour_manual(name = "Policy", values = c(pre = "red", post = "green")) + labs(title = "Avg_MELD and position in the offer list")

ggplot(temp[cond, ], mapping = aes(x = PTR_SEQUENCE_NUM_upd, y = avg_MELD)) + geom_line(aes(colour=factor(policy), group=factor(policy)))

cond = (temp$PTR_SEQUENCE_NUM_upd < 50)
ggplot(temp[cond, ], mapping = aes(x = PTR_SEQUENCE_NUM_upd, y = avg_MELD)) + geom_line(aes(colour=factor(yr), group=factor(yr)))
```

```{r}
summary(match$PTR_ROW_ORDER - match$PTR_SEQUENCE_NUM)
```

```{r}
# Patients with "Y" decision (for producing summary):
match_y = match[match$PTR_OFFER_ACPT == "Y", ]
quantile(match_y$PTR_SEQUENCE_NUM)[2]

temp = data.table(match_y)[, list(yes_per_month = .N/uniqueN(yr_mon)), by = list(yr)]
temp = temp[order(temp$yr), ]
plot(temp$yr, temp$yes_per_month)
ggplot2(aes(yr, yes_per_month), data = temp) + 


table(match_y$PTR_STAT_CD_desp)
summary(match_y$PTR_STAT_CD)

# Ignore recods with MELD/PELD < 6, and set MELD as 41 for Status 1A, 1B:
rem_MELD = c("MELD/PELD -1", "MELD/PELD -2", "MELD/PELD -3", "MELD/PELD -4", "MELD/PELD -5", "MELD/PELD -6", "MELD/PELD -7", "MELD/PELD -8", "MELD/PELD -9", "MELD/PELD -10", "MELD/PELD 0", "MELD/PELD 1", "MELD/PELD 2", "MELD/PELD 3", "MELD/PELD 4", "MELD/PELD 5")


match_y1 = match_y[!(match_y$PTR_STAT_CD_desp %in% rem_MELD), ] # Only 217 "Y" patients were removed.

# Function to set MELD as 41 for Status 1A/1B patients and of those with MELD > 40!
MELD_mod = function(x) {
  temp = strsplit(x, split = " ")[[1]][2]
  if ((temp == "1A") | (temp == "1B")) {
    return (41)
  } else if (as.numeric(temp) > 40) {
    return (41)
  } else return (as.numeric(temp))
}
MELD_mod("Status 1A"); MELD_mod("MELD/PELD 21")

match_y1$MELD = sapply(match_y1$PTR_STAT_CD_desp, function(x) {MELD_mod(x)})
table(match_y1$MELD)
```

# 
```{r}

```

```{r}

```




















